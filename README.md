# MLHW4

## შეჯიბრის აღწერა

"Challenges in Representation Learning: Facial Expression Recognition Challenge" არის 
Kaggle-ის შეჯიბრი, რომელიც ფოკუსირებულია სახის ემოციების კლასიფიკაციაზე. ეს ამოცანას მოიცავს ნეირონული ქსელების მოდელის 
შექმნას რომელიც, შეძლებს ადამიანის ემოციების ამოცნობას სახის ნიშნებიდან.


მეთოდოლოგია: დავიწყებთ მარტივი base მოდელით და თანდათანობით დავამატებთ სირთულეს, ყოველი გადაწყვეტილების დასაბუთებით.

---

## მოდელი 1: მარტივი CNN საბაზისო მოდელი

### არქიტექტურა


Input (1x48x48 სურათი)
    ↓
Conv2d(1→16 filters, 3x3 kernel) → ReLU → MaxPool(2x2)
    ↓
Conv2d(16→32 filters, 3x3 kernel) → ReLU → MaxPool(2x2)
    ↓
Flatten → Linear(4608→128) → ReLU → Dropout(0.5)
    ↓
Linear(128→7 classes) → Output


მარტივი მოდელით დავიწყე რადგან, მინდოდა მეგრძნო ზოგადად პრობლემის სირთულე, თუ მარტივი მოდელი ძალიან ცუდ შედეგს
დადებდა, ამით მივხვდებოდი რომ მიდგომა იყო არასწორი და პრობლემის არსი საერთოდ ვერ გამიგია. პლუს ცოტა დრო დაჭირდება.


### ახლა ცოტა დეტალურად თითოეული გადაწყვეტილება:

2 Convolutional Layer: ეს არის მინიმუმი, რაც საჭიროა იერარქიული ნიშნების ამოსაცნობად, პირველი layer: დაბალი დონის ნიშნები (წიბოები, კუთხეები)
     მეორე layer: უფრო რთული ნიშნები (ფორმები, texture-ები)
	 
16→32 Filters: მცირე რაოდენობაა რადგან ოვერფიტინგი ავიცილოთ თავიდან 48x48 სურათებზე, 16 ფილტრი პირველ layer-ში საკმარისია ძირითადი პატერნების დასაჭერად
                ხოლო 32 ფილტრი მეორე layer-ში უფრო რთული კომბინაციებისთვის.

3x3 Kernels: სტანდარტული არჩევანი ლოკალური პატერნების დასაჭერად სახის ნიშნებში.


Dropout 0.5: ჩვენი მოდელს შემთხვევაში არის ძირითადი რეგულარიზაცია overfitting-ის თავიდან ასაცილებლად, 
				0.5 სტანდარტული მნიშვნელობაა, არც ძალიან მაღალი, არც ძალიან დაბალი

### შედეგი:

ტრეინზე 52% იანი სიზუსტე, ხოლო ვალიდაციაზე 70. ცხადია ოვერფიტინგი გვაქვს, და თან იმასაც აჩვენებს რომ ზედმეტად მარტივი მოდელია და
უკეთესი შედეგის მიღება წესით უნდა შეიძლებოდეს.

---

## მოდელი 2: CNN გაუმჯობესებებით

### არქიტექტურა

Input (1x48x48)
    ↓
Conv2d(1→32) → BatchNorm2d → ReLU → MaxPool(2x2)  [48x48 → 24x24]
    ↓
Conv2d(32→64) → BatchNorm2d → ReLU → MaxPool(2x2)  [24x24 → 12x12]
    ↓
Conv2d(64→128) → BatchNorm2d → ReLU → MaxPool(2x2) [12x12 → 6x6]
    ↓
Conv2d(128→256) → BatchNorm2d → ReLU → MaxPool(2x2) [6x6 → 3x3]
    ↓
Flatten → Linear(2304→512) → BatchNorm1d → ReLU → Dropout(0.5)
    ↓
Linear(512→128) → ReLU → Dropout(0.25)
    ↓
Linear(128→7) → Output



მას შემდეგ, რაც ვნახე baseline performance, შევეცადე სავარაუდო პრობლემები მომეგვარებინა.

1. უფრო ღრმა ქსელი (4 Conv Layers), მოდელი 1 სავარაუდოდ underfitting-ს განიცდიდა, ძალიან მარტივი იყო რთული სახის ემოციებისთვის.
   
   ახლა დაახლოებით ასეთი დანაწილება გვექნება: პირველი layers: ძირითადი პატერნები (ხაზები, წირები), შუა layers სახის ნაწილები (თვალები, პირი, წარბები)
   და ბოლო layers ემოციური კომბინაციები.

2. Batch Normalization: მოდელ 1-ში შევნიშნე ნელი convergence ამიტომ BatchNorm დავამატე ყოველი conv layer-ის შემდეგ
   
   
3. მეტი Filters (32→64→128→256): ამის მიზეზი არის ის რომ, ღრმა layers-ს სჭირდება მეტი ფილტრები რთული კომბინაციების წარმოსაჩენად.
   

4. Learning Rate ოპტიმიზაცია: ფიქსირებული learning rate შეიძლება გადაცდეს ოპტიმალურ ქონვერჯენსს.
   
   გადაწყვეტა: StepLR scheduler LR-ის შემცირება ყოველ 20 epoch-ში.
   
   
5. Early Stopping: მოდელი 1ს შეიძლება overfitting განეცადა გვიან epochs-ში შესაბამისად, validation accuracy-ის 
		ვაკონტროლებ და როცა აღარ არის გაუმჯობესება ვწყვეტ.
   
6.  Weight Decay (1e-4): L2 რეგულარიზაციის პარამეტრების ზედმეტი ზრდისგან დასაცავად და თან ეხმარება მოდელს არ იყოს ძალიან კომპლექსური
   
   Gradient Clipping: უზრუნველყოფს სტაბილურ training-ს.

### შედეგი:

97 % ტრეინი, 58% ვალიდაცია. 8 პროცენტიანი ბუსტი გვაქ მარა ძაან დიდი ოვერფიტია მაინც, ბეჩნორმის და დროფაუთის მიუხედავად, მაინც არ მოგვარდა.


## მოდელი 3: ResNet

### არქიტექტურა


Input (1x48x48)
    ↓
Initial Block: Conv2d(1→64, 7x7, stride=2) → BatchNorm → ReLU → MaxPool
    ↓
Stage 1: 2x ResidualBlock(64→64) + CBAM Attention
    ↓
Stage 2: 2x ResidualBlock(64→128, stride=2) + CBAM Attention
    ↓
Stage 3: 2x ResidualBlock(128→256, stride=2) + CBAM Attention
    ↓
Stage 4: 2x ResidualBlock(256→512, stride=2) + CBAM Attention
    ↓
Global Average Pooling → Dropout(0.3) → Linear(512→7)



მოდელი 2-ის შედეგების საფუძველზე, მას შემდეგ, რაც ვნახე გაუმჯობესებული, მაგრამ კვლავ შეზღუდული performance, ვცადე შემდეგი გაუმჯობესებები:

1. Residual Connections (ResNet არქიტექტურა), მოდელი 2ს  vanishing gradient-ის პრობლემა აქ სადღაც 4+ layers იქით.
   
2. CBAM Attention Mechanism (Convolutional Block Attention Module): პრობლემა არის ის რომ სახის ყველა რეგიონი თანაბრად არის განხილული
 - არ ფოკუსირდება კრიტიკულ არეებზე.
   
   გადაწყვეტა: Channel + Spatial attention modules
   
 
3. Global Average Pooling:
   
   პრობლემა: Fully connected layers ამატებს overfitting risk-ს ამიტომ ვანაცვლებთ global average pooling-ით.
  
  
  დანარჩენი პარამეტრები გადაირჩა და ტრეინიც და ვალიდაციაც 60 პროცენტიან ნიშნულზე დაჯდა. ოვერფიტიც მოვაგვარეთ და ვალიდაციაზეც ასე თუ ისე ნორმალური შედეგი დაიდო.

